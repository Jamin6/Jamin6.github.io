<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Jamin">
    
    <title>
        
            GAN原理精讲与代码实战 |
        
        Jamin&#39;s Blog
    </title>
    
<link rel="stylesheet" href="/jamin6/css/style.css">

    <link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/Jamin6/image-hosting@main/image/1654439492406.7kyiyyuijls0.webp">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/css/font-awesome.min.css">
    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"jamin6.github.io","root":"/jamin6/","language":"zh-CN","path":"search.xml"};
    KEEP.theme_config = {"toc":{"enable":true,"number":false,"expand_all":true,"init_open":false},"style":{"primary_color":"#0066CC","avatar":"https://cdn.jsdelivr.net/gh/Jamin6/image-hosting@main/image/header.6rjn80v6u3o0.webp","favicon":"https://cdn.jsdelivr.net/gh/Jamin6/image-hosting@main/image/1654439492406.7kyiyyuijls0.webp","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":true,"scale":true},"first_screen":{"enable":true,"background_img":"https://gitee.com/jamin6/picgo/raw/master/images/bg.svg","description":"别人的话只能作为一种参考，是不能左右自己的。"},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":true}}},"local_search":{"enable":true,"preload":false},"code_copy":{"enable":true,"style":"mac"},"pjax":{"enable":true},"lazyload":{"enable":false},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"};
  </script>
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                Jamin&#39;s Blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/jamin6/"
                            >
                                首页
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/jamin6/archives"
                            >
                                归档
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/jamin6/categories"
                            >
                                分类
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/jamin6/tags"
                            >
                                标签
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/jamin6/about"
                            >
                                关于
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/jamin6/">首页</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/jamin6/archives">归档</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/jamin6/categories">分类</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/jamin6/tags">标签</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/jamin6/about">关于</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">GAN原理精讲与代码实战</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="https://cdn.jsdelivr.net/gh/Jamin6/image-hosting@main/image/header.6rjn80v6u3o0.webp">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Jamin</span>
                        
                            <span class="author-label">在校学生</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2023-07-11 15:59:00</span>
        <span class="mobile">2023-07-11 15:59</span>
    </span>
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/jamin6/categories/AI/">AI</a>&nbsp;
                    </li>
                
                    <li>
                        &gt; <a href="/jamin6/categories/AI/DL/">DL</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/jamin6/tags/GNN/">GNN</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/jamin6/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/">数据增强</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <h1 id="零、GAN原理精讲与代码实战"><a href="#零、GAN原理精讲与代码实战" class="headerlink" title="零、GAN原理精讲与代码实战"></a>零、GAN原理精讲与代码实战</h1><h1 id="一、GAN原理和结构"><a href="#一、GAN原理和结构" class="headerlink" title="一、GAN原理和结构"></a>一、GAN原理和结构</h1><h2 id="1、什么是GAN"><a href="#1、什么是GAN" class="headerlink" title="1、什么是GAN"></a>1、什么是GAN</h2><p>​        生成对抗网络（Generative Adversarial Networks，简称GAN）是当前人工智能学界最为重要的研究热点之一。其突出的生成对抗能力不仅可用于生成各类图像和自然语言数据，还启发和推动了各类半监督学习和无监督学习任务的发展。</p>
<p>​        GAN是一种深度神经网络架构，由一个生成网络和一个判别网络组成。生成网络产生“假”数据，并试图图欺骗判别网络;判别网络对生成数据进行真伪鉴别，试图正确识别所有”假”数据。在训练迭代的过程中，两个网络持续地进化和对抗,直到达到平衡状态(参考纳什均衡)，判别网络无法再识别“假”数据，训练结束。</p>
<h2 id="2、GAN原理"><a href="#2、GAN原理" class="headerlink" title="2、GAN原理"></a>2、GAN原理</h2><p>​        GAN模型主要包括了两个部分:</p>
<p>​        生成模型(Generative Model)和判别模型(Discriminative Model) ,也常叫做生成器(generator）与判别器(discriminator)。</p>
<h3 id="生成模型（生成器）"><a href="#生成模型（生成器）" class="headerlink" title="生成模型（生成器）"></a>生成模型（生成器）</h3><p>​        生成器主要用来学习真实图像分布从而让自身生成的图像更加真实，以骗过判别器。</p>
<h3 id="判别模型（判别器）"><a href="#判别模型（判别器）" class="headerlink" title="判别模型（判别器）"></a>判别模型（判别器）</h3><p>​        判别器则需要对接收的图片进行真假判别。</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>​        在训练过程中，生成器努力地让生成的图像更加真实,而判别器则努力地去识别出图像的真假，这个过程相当于一个二人博弈，随着时间的推移，生成器和判别器在不断地进行对抗。</p>
<p>​        最终两个网络达到了一个动态均衡:生成器生成的图像接近于真实图像分布，而判别器识别不出真假图像,对于给定图像的预测为真的概率基本接近0.5(相当于随机猜测尖别)。</p>
<h2 id="3、GAN模型结构"><a href="#3、GAN模型结构" class="headerlink" title="3、GAN模型结构"></a>3、GAN模型结构</h2><p>​    模型结构如下图所示：</p>
<p><img src="https://cdn.staticaly.com/gh/Jamin6/picx-images-hosting@master/image-20230711154035884.y0eztbee9m8.webp" alt="image-20230711154035884"></p>
<h2 id="4、损失函数"><a href="#4、损失函数" class="headerlink" title="4、损失函数"></a>4、损失函数</h2><p>​        GAN设计的关键在于损失函数的处理。对于判别模型，损失函数是容易定义的，判别器主要用来判断一张图片是真实的还是生成的，显然这是一个二分类问题。对于生成模型，损失函数的定义就不是那么容易。我们希望生成器可以生成接近真实的图片，对于生成的图片是否像真实的，我们人类肉眼容易判断，但具体到代码中，往往是一个抽象的，难以数学公理化定义的范式。</p>
<p>​        针对这个问题，我们不妨把生成模型的输出，交给判别模型处理，让判别器来判断这是一个真实的图像还是假的图像，因为深度学习模型很适合做图片的分类。这样就将生成对抗网络中的两大类模型生成器与判别器紧密地联合在了一起。</p>
<h1 id="二、GAN算法流程与公式"><a href="#二、GAN算法流程与公式" class="headerlink" title="二、GAN算法流程与公式"></a>二、GAN算法流程与公式</h1><h2 id="1、算法流程"><a href="#1、算法流程" class="headerlink" title="1、算法流程"></a>1、算法流程</h2><p>​        GAN这个结构的最精妙之处在于对生成模型损失函数的处理，这里以生成图片为例，说明其整个算法流程。假设我们有两个网络：G(Generator)和D (Discriminator)。</p>
<ul>
<li>G是一个生成图片的网络，它接收一个随机的噪声z，通过这个噪声生成图片，记做G(z)。</li>
<li>D是一个判别网络，判别一张图片是不是“真实的”。它的输入参数是x，x代表一张图片，输出D(x)代表x为真实图片的概率，如果为1,就代表100%是真实的图片，而输出为0，就代表不可能是真实的图片。</li>
</ul>
<p>​        在训练过程中，将随机噪声输入生成网络G，得到生成的图片；判别器接收生成的图片和真实的图片，并尽量将两者区分开来。在这个计算过程中，能否正确区分生成的图片和真实的图片将作为判别器的损失，而能否生成近似真实的图片并使得判别器将生成的图片判定为真将作为生成器的损失。</p>
<p>​        <strong>注</strong>：生成器的损失是通过判别器的输出来计算的,而判别器的输出是一个概率值，我们可以通过交叉嫡计算。</p>
<h2 id="2、GAN公式"><a href="#2、GAN公式" class="headerlink" title="2、GAN公式"></a>2、GAN公式</h2><p>​        Goodfellow从理论上证明了GAN算法的收敛性以及在模型收敛时生成数据具有和真实数据相同的分布。<br>​        GAN的公式如图：</p>
<img src="https://cdn.staticaly.com/gh/Jamin6/picx-images-hosting@master/image-20230711161912533.1zrpmvuedvts.webp" alt="image-20230711161912533" style="zoom: 33%;" />

<p>​        公式中x表示真实图片，z表示输入G网络的噪声，G(z)表示G网络生成的图片，D(*)表示D网络判断图片是否真实的概率。</p>
<ul>
<li>从判别器D的角度，希望最大化V(D,G)</li>
<li>从生成器G的角度，希望最小化V(D,G)</li>
</ul>
<h2 id="3、GAN应用领域"><a href="#3、GAN应用领域" class="headerlink" title="3、GAN应用领域"></a>3、GAN应用领域</h2><ul>
<li>图片生成：生成一些假数据，比如海报种的人脸</li>
<li>图像增强：从分割图种生成假的真实街景，方标训练无人汽车。</li>
<li>风格化和艺术的图像创造：转换图像风格，修补图像。</li>
<li>变声：一个人的声音转为另一个人的声音；去除噪声等。</li>
</ul>
<h1 id="三、GAN实战"><a href="#三、GAN实战" class="headerlink" title="三、GAN实战"></a>三、GAN实战</h1><p>这里采用Mnist数据集。</p>
<h2 id="1、导包"><a href="#1、导包" class="headerlink" title="1、导包"></a>1、导包</h2><p>导入常用的包：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></table></figure>

<h2 id="2、预设置"><a href="#2、预设置" class="headerlink" title="2、预设置"></a>2、预设置</h2><p>预设置参数和设备等信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">os.environ[<span class="string">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>] = <span class="string">&quot;TRUE&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设备</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">lr = <span class="number">0.0001</span></span><br><span class="line">test_input = torch.randn(<span class="number">16</span>, <span class="number">100</span>, device=device)</span><br></pre></td></tr></table></figure>

<h2 id="3、准备数据集"><a href="#3、准备数据集" class="headerlink" title="3、准备数据集"></a>3、准备数据集</h2><p>准备数据集并做对应的处理：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据准备</span></span><br><span class="line"><span class="comment"># 对数据做归一化  （-1, 1）</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [</span><br><span class="line">        <span class="comment"># 该方法会做(0,1)的归一化，并将结构改为C.H.W，还会转为Tensor类型</span></span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        <span class="comment"># 归一化  参数(均值,方差) 开始在(0,1)，要变为(-1,1)，所以参数为(0.5，0.5)</span></span><br><span class="line">        transforms.Normalize(<span class="number">0.5</span>, <span class="number">0.5</span>)</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、准备数据集</span></span><br><span class="line">train_ds = torchvision.datasets.MNIST(<span class="string">&quot;mnist_data&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">                                     transform=transform</span><br><span class="line">                                     )</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;==========【数据集加载完成】==========&quot;</span>)</span><br><span class="line">dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h2 id="4、定义生成器和判别器"><a href="#4、定义生成器和判别器" class="headerlink" title="4、定义生成器和判别器"></a>4、定义生成器和判别器</h2><p>生成器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 2、定义生成器</span></span><br><span class="line"><span class="comment">#     输入是长度为100的随机噪声（正态分布随机数）</span></span><br><span class="line"><span class="comment">#     输出为(1,28,28)的图片</span></span><br><span class="line"><span class="comment">#   linear 1: 100 -&gt; 256</span></span><br><span class="line"><span class="comment">#   linear 2: 256 -&gt; 512</span></span><br><span class="line"><span class="comment">#   linear 3: 512 -&gt; 28*28</span></span><br><span class="line"><span class="comment">#   linear 4: 28*28 -&gt; reshape(1,28,28)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line">        self.main = nn.Sequential(</span><br><span class="line">            <span class="comment"># linear参数(in_channel, out_channel)</span></span><br><span class="line">            nn.Linear(<span class="number">100</span>, <span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">28</span>*<span class="number">28</span>),</span><br><span class="line">            <span class="comment"># 在GAN中，最后一层的激活层采用Tanh效果较好(经验)</span></span><br><span class="line">            nn.Tanh()           <span class="comment"># (-1, 1)</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 得到 28*28 的 序列</span></span><br><span class="line">        img = self.main(x)</span><br><span class="line">        <span class="comment"># reshape (1,28,28)</span></span><br><span class="line">        img = img.view(-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure>

<p>判别器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 3、定义判别器</span></span><br><span class="line"><span class="comment">#     输入：(1,28,28)的图片</span></span><br><span class="line"><span class="comment">#     输出：二分类的概率值（输出使用Sigmod激活 0-1）</span></span><br><span class="line"><span class="comment">#       BCELoss 计算交叉熵损失</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line">        self.main = nn.Sequential(</span><br><span class="line">        <span class="comment"># linear参数(in_channel, out_channel)</span></span><br><span class="line">        nn.Linear(<span class="number">28</span>*<span class="number">28</span>, <span class="number">512</span>),</span><br><span class="line">        <span class="comment"># 相比ReLu，该激活方法会保留一定的梯度</span></span><br><span class="line">            <span class="comment"># f(x) :  x&gt;0 输出 x, x&lt;0 输出 a*x  a是一个很小的斜率 如0.01，0.002等</span></span><br><span class="line">        <span class="comment"># 在判别器中一般推荐使用LeakyReLU激活</span></span><br><span class="line">        nn.LeakyReLU(),</span><br><span class="line">        nn.Linear(<span class="number">512</span>, <span class="number">256</span>),</span><br><span class="line">        nn.LeakyReLU(),</span><br><span class="line">        nn.Linear(<span class="number">256</span>, <span class="number">1</span>),</span><br><span class="line">        nn.Sigmoid()</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">        x = self.main(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<h2 id="5、模型等初始化"><a href="#5、模型等初始化" class="headerlink" title="5、模型等初始化"></a>5、模型等初始化</h2><p>初始化模型、优化器和损失函数等：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 4、初始化</span></span><br><span class="line"><span class="comment">#   g</span></span><br><span class="line">gen = Generator().to(device)</span><br><span class="line"><span class="comment">#   d</span></span><br><span class="line">dis = Discriminator().to(device)</span><br><span class="line"><span class="comment">#   优化器</span></span><br><span class="line">d_optim = torch.optim.Adam(dis.parameters(), lr=lr)</span><br><span class="line">g_optim = torch.optim.Adam(gen.parameters(), lr=lr)</span><br><span class="line"><span class="comment">#   损失函数</span></span><br><span class="line">loss_fn = torch.nn.BCELoss()</span><br></pre></td></tr></table></figure>

<h2 id="6、绘制图像等操作"><a href="#6、绘制图像等操作" class="headerlink" title="6、绘制图像等操作"></a>6、绘制图像等操作</h2><p>编写图像绘制方法等：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 5、绘制图像</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gen_img_plot</span>(<span class="params">model, test_input</span>):</span><br><span class="line">    prediction = np.squeeze(model(test_input).detach().cpu().numpy())</span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">4</span>,<span class="number">4</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>):</span><br><span class="line">        plt.subplot(<span class="number">4</span>, <span class="number">4</span>, i+<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># +1  /2  是为了将(-1,1)转为(0,1)</span></span><br><span class="line">        plt.imshow((prediction[i] + <span class="number">1</span>) / <span class="number">2</span>)</span><br><span class="line">        plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="7、模型训练和效果查看"><a href="#7、模型训练和效果查看" class="headerlink" title="7、模型训练和效果查看"></a>7、模型训练和效果查看</h2><p>模型训练：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 6、GAN训练</span></span><br><span class="line">D_Loss = []</span><br><span class="line">G_Loss = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练循环</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    d_epoch_loss = <span class="number">0</span></span><br><span class="line">    g_epoch_loss = <span class="number">0</span></span><br><span class="line">    count = <span class="built_in">len</span>(dataloader)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> step, (img, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        img = img.to(device)</span><br><span class="line">        size = img.size(<span class="number">0</span>)</span><br><span class="line">        random_noise = torch.randn(size, <span class="number">100</span>, device=device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 梯度归0</span></span><br><span class="line">        d_optim.zero_grad()</span><br><span class="line">        <span class="comment"># 对判别器输入真实图片  real_img_output 真实图片的识别结果</span></span><br><span class="line">        real_img_output = dis(img)</span><br><span class="line">        <span class="comment"># 判别器在真实图片上的损失</span></span><br><span class="line">        d_real_img_loss = loss_fn(real_img_output, torch.ones_like(real_img_output))</span><br><span class="line">        <span class="comment"># 计算梯度</span></span><br><span class="line">        d_real_img_loss.backward()</span><br><span class="line">        <span class="comment"># 生成假图片</span></span><br><span class="line">        gen_img = gen(random_noise)</span><br><span class="line">        <span class="comment"># 输入假图片给判别器</span></span><br><span class="line">        fake_img_output = dis(gen_img.detach())</span><br><span class="line">        <span class="comment"># 判别器在假图片上的损失</span></span><br><span class="line">        d_fake_img_loss = loss_fn(fake_img_output, torch.zeros_like(real_img_output))</span><br><span class="line">        <span class="comment"># 计算梯度</span></span><br><span class="line">        d_fake_img_loss.backward()</span><br><span class="line">        <span class="comment"># 判别器的总损失</span></span><br><span class="line">        d_loss = d_real_img_loss + d_fake_img_loss</span><br><span class="line">        <span class="comment"># 判别器，优化</span></span><br><span class="line">        d_optim.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 生成器梯度归0</span></span><br><span class="line">        g_optim.zero_grad()</span><br><span class="line">        fake_img_output = dis(gen_img)</span><br><span class="line">        <span class="comment"># 生成器的损失</span></span><br><span class="line">        g_loss = loss_fn(fake_img_output, torch.ones_like(real_img_output))</span><br><span class="line">        <span class="comment"># 计算梯度</span></span><br><span class="line">        g_loss.backward()</span><br><span class="line">        <span class="comment"># 生成器，优化</span></span><br><span class="line">        g_optim.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算每一个epoch的总g_loss,d_loss</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            g_epoch_loss += g_loss</span><br><span class="line">            d_epoch_loss += d_loss</span><br><span class="line">    <span class="comment"># 每一个epoch的平均loss</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        g_epoch_loss /= count</span><br><span class="line">        d_epoch_loss /= count</span><br><span class="line">        <span class="comment"># 存放每个epoch的平均Loss</span></span><br><span class="line">        D_Loss.append(d_epoch_loss)</span><br><span class="line">        G_Loss.append(g_epoch_loss)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Epoch: &quot;</span>, epoch + <span class="number">1</span>)</span><br><span class="line">        gen_img_plot(gen, test_input)</span><br></pre></td></tr></table></figure>

<p>效果查看：</p>
<p><img src="https://cdn.staticaly.com/gh/Jamin6/picx-images-hosting@master/image-20230712165443632.3hk7byk9hn00.webp" alt="image-20230712165443632"></p>
<p><img src="https://cdn.staticaly.com/gh/Jamin6/picx-images-hosting@master/image-20230712165500497.1k1n4qg28ra8.webp" alt="image-20230712165500497"></p>
<p><img src="https://cdn.staticaly.com/gh/Jamin6/picx-images-hosting@master/image-20230712165524474.20valucl4hkw.webp" alt="image-20230712165524474"></p>
<p><img src="https://cdn.staticaly.com/gh/Jamin6/picx-images-hosting@master/image-20230712165543210.4lokli95z940.webp" alt="image-20230712165543210"></p>
<h1 id="四、整体代码"><a href="#四、整体代码" class="headerlink" title="四、整体代码"></a>四、整体代码</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>] = <span class="string">&quot;TRUE&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设备</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">lr = <span class="number">0.0001</span></span><br><span class="line">test_input = torch.randn(<span class="number">16</span>, <span class="number">100</span>, device=device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据准备</span></span><br><span class="line"><span class="comment"># 对数据做归一化  （-1, 1）</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [</span><br><span class="line">        <span class="comment"># 该方法会做(0,1)的归一化，并将结构改为C.H.W，还会转为Tensor类型</span></span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        <span class="comment"># 归一化  参数(均值,方差) 开始在(0,1)，要变为(-1,1)，所以参数为(0.5，0.5)</span></span><br><span class="line">        transforms.Normalize(<span class="number">0.5</span>, <span class="number">0.5</span>)</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、准备数据集</span></span><br><span class="line">train_ds = torchvision.datasets.MNIST(<span class="string">&quot;mnist_data&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">                                     transform=transform</span><br><span class="line">                                     )</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;==========【数据集加载完成】==========&quot;</span>)</span><br><span class="line">dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、定义生成器</span></span><br><span class="line"><span class="comment">#     输入是长度为100的随机噪声（正态分布随机数）</span></span><br><span class="line"><span class="comment">#     输出为(1,28,28)的图片</span></span><br><span class="line"><span class="comment">#   linear 1: 100 -&gt; 256</span></span><br><span class="line"><span class="comment">#   linear 2: 256 -&gt; 512</span></span><br><span class="line"><span class="comment">#   linear 3: 512 -&gt; 28*28</span></span><br><span class="line"><span class="comment">#   linear 4: 28*28 -&gt; reshape(1,28,28)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line">        self.main = nn.Sequential(</span><br><span class="line">            <span class="comment"># linear参数(in_channel, out_channel)</span></span><br><span class="line">            nn.Linear(<span class="number">100</span>, <span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">28</span>*<span class="number">28</span>),</span><br><span class="line">            <span class="comment"># 在GAN中，最后一层的激活层采用Tanh效果较好(经验)</span></span><br><span class="line">            nn.Tanh()           <span class="comment"># (-1, 1)</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 得到 28*28 的 序列</span></span><br><span class="line">        img = self.main(x)</span><br><span class="line">        <span class="comment"># reshape (1,28,28)</span></span><br><span class="line">        img = img.view(-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、定义判别器</span></span><br><span class="line"><span class="comment">#     输入：(1,28,28)的图片</span></span><br><span class="line"><span class="comment">#     输出：二分类的概率值（输出使用Sigmod激活 0-1）</span></span><br><span class="line"><span class="comment">#       BCELoss 计算交叉熵损失</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line">        self.main = nn.Sequential(</span><br><span class="line">        <span class="comment"># linear参数(in_channel, out_channel)</span></span><br><span class="line">        nn.Linear(<span class="number">28</span>*<span class="number">28</span>, <span class="number">512</span>),</span><br><span class="line">        <span class="comment"># 相比ReLu，该激活方法会保留一定的梯度</span></span><br><span class="line">            <span class="comment"># f(x) :  x&gt;0 输出 x, x&lt;0 输出 a*x  a是一个很小的斜率 如0.01，0.002等</span></span><br><span class="line">        <span class="comment"># 在判别器中一般推荐使用LeakyReLU激活</span></span><br><span class="line">        nn.LeakyReLU(),</span><br><span class="line">        nn.Linear(<span class="number">512</span>, <span class="number">256</span>),</span><br><span class="line">        nn.LeakyReLU(),</span><br><span class="line">        nn.Linear(<span class="number">256</span>, <span class="number">1</span>),</span><br><span class="line">        nn.Sigmoid()</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">        x = self.main(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、初始化</span></span><br><span class="line"><span class="comment">#   g</span></span><br><span class="line">gen = Generator().to(device)</span><br><span class="line"><span class="comment">#   d</span></span><br><span class="line">dis = Discriminator().to(device)</span><br><span class="line"><span class="comment">#   优化器</span></span><br><span class="line">d_optim = torch.optim.Adam(dis.parameters(), lr=lr)</span><br><span class="line">g_optim = torch.optim.Adam(gen.parameters(), lr=lr)</span><br><span class="line"><span class="comment">#   损失函数</span></span><br><span class="line">loss_fn = torch.nn.BCELoss()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、绘制图像</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gen_img_plot</span>(<span class="params">model, test_input</span>):</span><br><span class="line">    prediction = np.squeeze(model(test_input).detach().cpu().numpy())</span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">4</span>,<span class="number">4</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>):</span><br><span class="line">        plt.subplot(<span class="number">4</span>, <span class="number">4</span>, i+<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># +1  /2  是为了将(-1,1)转为(0,1)</span></span><br><span class="line">        plt.imshow((prediction[i] + <span class="number">1</span>) / <span class="number">2</span>)</span><br><span class="line">        plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 6、GAN训练</span></span><br><span class="line">D_Loss = []</span><br><span class="line">G_Loss = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练循环</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    d_epoch_loss = <span class="number">0</span></span><br><span class="line">    g_epoch_loss = <span class="number">0</span></span><br><span class="line">    count = <span class="built_in">len</span>(dataloader)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> step, (img, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        img = img.to(device)</span><br><span class="line">        size = img.size(<span class="number">0</span>)</span><br><span class="line">        random_noise = torch.randn(size, <span class="number">100</span>, device=device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 梯度归0</span></span><br><span class="line">        d_optim.zero_grad()</span><br><span class="line">        <span class="comment"># 对判别器输入真实图片  real_img_output 真实图片的识别结果</span></span><br><span class="line">        real_img_output = dis(img)</span><br><span class="line">        <span class="comment"># 判别器在真实图片上的损失</span></span><br><span class="line">        d_real_img_loss = loss_fn(real_img_output, torch.ones_like(real_img_output))</span><br><span class="line">        <span class="comment"># 计算梯度</span></span><br><span class="line">        d_real_img_loss.backward()</span><br><span class="line">        <span class="comment"># 生成假图片</span></span><br><span class="line">        gen_img = gen(random_noise)</span><br><span class="line">        <span class="comment"># 输入假图片给判别器</span></span><br><span class="line">        fake_img_output = dis(gen_img.detach())</span><br><span class="line">        <span class="comment"># 判别器在假图片上的损失</span></span><br><span class="line">        d_fake_img_loss = loss_fn(fake_img_output, torch.zeros_like(real_img_output))</span><br><span class="line">        <span class="comment"># 计算梯度</span></span><br><span class="line">        d_fake_img_loss.backward()</span><br><span class="line">        <span class="comment"># 判别器的总损失</span></span><br><span class="line">        d_loss = d_real_img_loss + d_fake_img_loss</span><br><span class="line">        <span class="comment"># 判别器，优化</span></span><br><span class="line">        d_optim.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 生成器梯度归0</span></span><br><span class="line">        g_optim.zero_grad()</span><br><span class="line">        fake_img_output = dis(gen_img)</span><br><span class="line">        <span class="comment"># 生成器的损失</span></span><br><span class="line">        g_loss = loss_fn(fake_img_output, torch.ones_like(real_img_output))</span><br><span class="line">        <span class="comment"># 计算梯度</span></span><br><span class="line">        g_loss.backward()</span><br><span class="line">        <span class="comment"># 生成器，优化</span></span><br><span class="line">        g_optim.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算每一个epoch的总g_loss,d_loss</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            g_epoch_loss += g_loss</span><br><span class="line">            d_epoch_loss += d_loss</span><br><span class="line">    <span class="comment"># 每一个epoch的平均loss</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        g_epoch_loss /= count</span><br><span class="line">        d_epoch_loss /= count</span><br><span class="line">        <span class="comment"># 存放每个epoch的平均Loss</span></span><br><span class="line">        D_Loss.append(d_epoch_loss)</span><br><span class="line">        G_Loss.append(g_epoch_loss)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Epoch: &quot;</span>, epoch + <span class="number">1</span>)</span><br><span class="line">        gen_img_plot(gen, test_input)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul>
        <li>本文标题：GAN原理精讲与代码实战</li>
        <li>本文作者：Jamin</li>
        <li>创建时间：2023-07-11 15:59:00</li>
        <li>
            本文链接：https://jamin6.github.io/2023/07/11/GAN原理精讲与代码实战/
        </li>
        <li>
            版权声明：本博客所有文章除特别声明外，均采用 <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> 许可协议。转载请注明出处！
        </li>
    </ul>
</div>

            </div>
        

        
            <ul class="post-tags-box">
                
                    <li class="tag-item">
                        <a href="/jamin6/tags/GNN/">#GNN</a>&nbsp;
                    </li>
                
                    <li class="tag-item">
                        <a href="/jamin6/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/">#数据增强</a>&nbsp;
                    </li>
                
            </ul>
        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/jamin6/2023/07/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%96%B9%E6%B3%95(%E5%87%BD%E6%95%B0)/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">机器学习中常用的方法(函数)</span>
                                <span class="post-nav-item">上一篇</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/jamin6/2023/07/10/Hexo%E4%B8%8A%E4%BC%A0%E6%95%99%E7%A8%8B/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Hexo上传教程</span>
                                <span class="post-nav-item">下一篇</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
            <div class="comment-container">
                <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments">&nbsp;评论</i>
    </div>
    

        
            
    <div class="valine-container">
        <script data-pjax
                src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script>
        <div id="vcomments"></div>
        <script data-pjax>
            function loadValine() {
                new Valine({
                    el: '#vcomments',
                    appId: 'aDovJfU0RQy3TJemE3IuhzKs-gzGzoHsz',
                    appKey: 'QUwMEPNfLi8k1CnCV4Jj2pz5',
                    meta: ['nick', 'mail', 'link'],
                    avatar: 'wavatar',
                    enableQQ: true,
                    placeholder: '😜 尽情吐槽吧~',
                    lang: 'zh-CN'.toLowerCase()
                });

                function getAuthor(language) {
                    switch (language) {
                        case 'en':
                            return 'Author';
                        case 'zh-CN':
                            return '博主';
                        default:
                            return 'Master';
                    }
                }

                // Add "Author" identify
                const getValineDomTimer = setInterval(() => {
                    const vcards = document.querySelectorAll('#vcomments .vcards .vcard');
                    if (vcards.length > 0) {
                        let author = 'Jamin';

                        if (author) {
                            for (let vcard of vcards) {
                                const vnick_dom = vcard.querySelector('.vhead .vnick');
                                const vnick = vnick_dom.innerHTML;
                                if (vnick === author) {
                                    vnick_dom.innerHTML = `${vnick} <span class="author">${getAuthor(KEEP.hexo_config.language)}</span>`
                                }
                            }
                        }
                        clearInterval(getValineDomTimer);
                    } else {
                        clearInterval(getValineDomTimer);
                    }
                }, 2000);
            }

            if ('true') {
                const loadValineTimeout = setTimeout(() => {
                    loadValine();
                    clearTimeout(loadValineTimeout);
                }, 1000);
            } else {
                window.addEventListener('DOMContentLoaded', loadValine);
            }
        </script>
    </div>



        
    
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2022</span>
              -
            
            2024&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Jamin</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        访问人数&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
                    <span id="busuanzi_container_site_pv">
                        总访问量&nbsp;<span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            由 <a target="_blank" href="https://hexo.io">Hexo</a> 驱动&nbsp;|&nbsp;主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fas fa-comment"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%9B%B6%E3%80%81GAN%E5%8E%9F%E7%90%86%E7%B2%BE%E8%AE%B2%E4%B8%8E%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98"><span class="nav-text">零、GAN原理精讲与代码实战</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%80%E3%80%81GAN%E5%8E%9F%E7%90%86%E5%92%8C%E7%BB%93%E6%9E%84"><span class="nav-text">一、GAN原理和结构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1%E3%80%81%E4%BB%80%E4%B9%88%E6%98%AFGAN"><span class="nav-text">1、什么是GAN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2%E3%80%81GAN%E5%8E%9F%E7%90%86"><span class="nav-text">2、GAN原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%EF%BC%88%E7%94%9F%E6%88%90%E5%99%A8%EF%BC%89"><span class="nav-text">生成模型（生成器）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%88%A4%E5%88%AB%E5%99%A8%EF%BC%89"><span class="nav-text">判别模型（判别器）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%9F%E7%90%86"><span class="nav-text">原理</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3%E3%80%81GAN%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="nav-text">3、GAN模型结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4%E3%80%81%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-text">4、损失函数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%8C%E3%80%81GAN%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B%E4%B8%8E%E5%85%AC%E5%BC%8F"><span class="nav-text">二、GAN算法流程与公式</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1%E3%80%81%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="nav-text">1、算法流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2%E3%80%81GAN%E5%85%AC%E5%BC%8F"><span class="nav-text">2、GAN公式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3%E3%80%81GAN%E5%BA%94%E7%94%A8%E9%A2%86%E5%9F%9F"><span class="nav-text">3、GAN应用领域</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%89%E3%80%81GAN%E5%AE%9E%E6%88%98"><span class="nav-text">三、GAN实战</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1%E3%80%81%E5%AF%BC%E5%8C%85"><span class="nav-text">1、导包</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2%E3%80%81%E9%A2%84%E8%AE%BE%E7%BD%AE"><span class="nav-text">2、预设置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3%E3%80%81%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">3、准备数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4%E3%80%81%E5%AE%9A%E4%B9%89%E7%94%9F%E6%88%90%E5%99%A8%E5%92%8C%E5%88%A4%E5%88%AB%E5%99%A8"><span class="nav-text">4、定义生成器和判别器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5%E3%80%81%E6%A8%A1%E5%9E%8B%E7%AD%89%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="nav-text">5、模型等初始化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6%E3%80%81%E7%BB%98%E5%88%B6%E5%9B%BE%E5%83%8F%E7%AD%89%E6%93%8D%E4%BD%9C"><span class="nav-text">6、绘制图像等操作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7%E3%80%81%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%92%8C%E6%95%88%E6%9E%9C%E6%9F%A5%E7%9C%8B"><span class="nav-text">7、模型训练和效果查看</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E6%95%B4%E4%BD%93%E4%BB%A3%E7%A0%81"><span class="nav-text">四、整体代码</span></a></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="搜索..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>



<script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/dark-light-toggle.js"></script>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/local-search.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/code-copy.js"></script>




<div class="post-scripts pjax">
    
        <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/left-side-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/libs/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/toc.js"></script>
    
</div>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/libs/pjax.min.js"></script>
<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
